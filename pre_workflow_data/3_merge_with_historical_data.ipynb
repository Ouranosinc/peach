{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge historical and real-time data\n",
    "\n",
    "\n",
    "Function of script:\n",
    "* Get latest valid date of historical water level data\n",
    "* Retain real-time data only after this date\n",
    "* Concatenate historical data and real-time data into one file\n",
    "\n",
    "Context in workflow:\n",
    "* If there is no real-time data for a given station, the historical data will be copied to the next folder (essentially skipping the merge step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import pytz\n",
    "from pathlib import Path\n",
    "\n",
    "DATA = Path(\"data\")\n",
    "INPUTS = DATA / \"inputs\"\n",
    "OUTPUTS = DATA / \"outputs\"\n",
    "\n",
    "stnlist_csv = INPUTS / \"metadata.csv\"\n",
    "input_dir_old = INPUTS / \"wl_historical\"\n",
    "input_dir_new = OUTPUTS / \"wl_realtime\"\n",
    "output_dir = OUTPUTS / \"wl_merged\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 - Get list of real-time stations on the CHS API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urllib.request.urlopen('https://api-iwls.dfo-mpo.gc.ca/api/v1/stations') as url:\n",
    "    data = json.loads(url.read().decode())\n",
    "chs_api_stns = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - Add latest years to historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tz_from_str(tz_str):\n",
    "    \"\"\"Converts a timezone string (e.g., 'UTC-4' or 'UTC-3:30') to a pytz timezone object.\"\"\"\n",
    "    if tz_str.startswith(\"UTC\"):\n",
    "        offset = tz_str[3:]\n",
    "        hours, minutes = map(int, offset.split(':')) if ':' in offset else (int(offset), 0)\n",
    "        return pytz.FixedOffset(hours * 60 - minutes)\n",
    "    return None\n",
    "\n",
    "stnlist = pd.read_csv(stnlist_csv, encoding='latin1')\n",
    "\n",
    "for i, row in stnlist.iterrows():\n",
    "    stn_num = str(row['stn_num']).zfill(5)\n",
    "    stn_name = row['stn_name']\n",
    "    tz = get_tz_from_str(row['lcl_stnd_tz'])\n",
    "    file = os.path.join(input_dir_new, f'{stn_num}_realtime_wl.csv')\n",
    "    old_data = os.path.join(input_dir_old, f'{stn_num}_HOURLY.DAT')\n",
    "    all_data = os.path.join(output_dir, f'{stn_num}_HOURLY.DAT')\n",
    "\n",
    "    # Assume that missing files means that station didn't have any real-time data,\n",
    "    if not os.path.exists(file):\n",
    "        shutil.copy(old_data, all_data)\n",
    "        continue\n",
    "\n",
    "    new_data = pd.read_csv(file, index_col=0, parse_dates=True)\n",
    "\n",
    "    with open(old_data, \"r\", encoding=\"latin1\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    latest_lst = None\n",
    "    for line in reversed(lines):\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) == 3:\n",
    "            date, time, value = parts\n",
    "            try:\n",
    "                value = float(value)\n",
    "                if value != 999.999:\n",
    "                    latest_lst = f\"{date} {time}\"\n",
    "                    break\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    latest_lst_dt = pd.to_datetime(latest_lst, format='%Y/%m/%d %H:%M')\n",
    "    latest_lst_dt = tz.localize(latest_lst_dt)\n",
    "    latest_utc_dt = latest_lst_dt.astimezone(pytz.utc)\n",
    "    new_data_cropped = new_data[new_data.index > latest_utc_dt]\n",
    "\n",
    "    new_lines = []\n",
    "    for timestamp, row in new_data_cropped.iterrows():\n",
    "        event_time = timestamp.to_pydatetime()\n",
    "        date_str = event_time.strftime(\"%Y/%m/%d\")\n",
    "        time_str = event_time.strftime(\"%H:%M\")\n",
    "        value_str = f\"{row['value']:7.3f}\"\n",
    "        new_lines.append(f\"{date_str} {time_str} {value_str}\\n\")\n",
    "\n",
    "    with open(all_data, \"w\", encoding=\"latin1\") as f:\n",
    "        f.writelines(lines)\n",
    "        f.writelines(new_lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
