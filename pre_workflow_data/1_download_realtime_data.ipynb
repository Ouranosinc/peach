{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download latest WLs (real-time data from CHS API)\n",
    "\n",
    "Function of script:\n",
    "* Download real-time data between the start_yr and end_yr specified\n",
    "\n",
    "Context in workflow:\n",
    "* This script can be used in two ways \n",
    "    * to compare the historical and real-time datasets. For this, use an older start date (e.g., 2000).\n",
    "    * to add recent years without overlap. For this, use a more recent start date (e.g., 2023).\n",
    "* If you only want to process historical data, you can skip this step and the merge step and go directly from metadata to preproc, as long as you update the paths in the preproc step.\n",
    "\n",
    "Notes: \n",
    "* I've already checked that the real-time stations match the historical stations in terms of timezone and datum (not shown).\n",
    "* Some stations don't have real-time data. For these, no file is downloaded.\n",
    "* Currently have a skip for Fulford Harbour (07330), which does not have real-time data.\n",
    "* API docs:\n",
    "    * https://tides.gc.ca/tides/node/215\n",
    "    * https://api-iwls.dfo-mpo.gc.ca/swagger-ui/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "import time\n",
    "import json\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "start_yr = 2023\n",
    "end_yr = 2025\n",
    "\n",
    "DATA = Path(\"data\")\n",
    "\n",
    "stnlist_csv = DATA / \"inputs\" / \"metadata.csv\"\n",
    "output_dir = DATA / \"outputs\" / \"wl_realtime\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "def sid_from_code(code: str):\n",
    "    \"\"\"Return the station ID from the station code.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    code : str\n",
    "        Station code, e.g., \"08860\"\n",
    "    \"\"\"\n",
    "    url = f\"https://api-iwls.dfo-mpo.gc.ca/api/v1/stations?code={code}\"\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        data = json.loads(response.read().decode())\n",
    "    return data[0]['id']\n",
    "\n",
    "def real_time_data(code: str, start: dt.datetime, end: dt.datetime) -> pd.DataFrame:\n",
    "    \"\"\"Return hourly sea level time series from station data from the \n",
    "    Integrated Water Level System of the Canadian Hydrographic Service.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sid : str\n",
    "      Station code, e.g. \"00490\" for the Halifax station.\n",
    "    start : dt.datetime\n",
    "      Start date. \n",
    "    end : dt.datetime.\n",
    "      End date.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "      Hourly water level time series.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    https://api.iwls-sine.azure.cloud-nuage.dfo-mpo.gc.ca/swagger-ui/index.html\n",
    "    \"\"\"\n",
    "    api = \"https://api-iwls.dfo-mpo.gc.ca/api/v1\"\n",
    "    sid = sid_from_code(code)\n",
    "    s = start\n",
    "    raw = []\n",
    "    while s < end:\n",
    "        # The API might grumble for long requests, so limit to one month at a time.\n",
    "        e = min(s + pd.DateOffset(months=1), end)\n",
    "        \n",
    "        start_str = s.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        end_str = e.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        \n",
    "        url = f\"{api}/stations/{sid}/data?time-series-code=wlo&from={start_str}&to={end_str}&resolution=SIXTY_MINUTES\"\n",
    "\n",
    "        try:\n",
    "            with urllib.request.urlopen(url) as response:\n",
    "                data = json.loads(response.read().decode())\n",
    "                raw.extend(data)\n",
    "                time.sleep(1) \n",
    "        except Exception as err:\n",
    "            print(f\"Error fetching data: {err}\\n{url}\")\n",
    "        \n",
    "        s = e\n",
    "    \n",
    "    if raw:\n",
    "        # Convert raw data to DataFrame    \n",
    "        df = pd.DataFrame(raw)\n",
    "        df['eventDate'] = pd.to_datetime(df['eventDate'])\n",
    "        df = df.drop(columns=['timeSeriesId'])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stnlist = pd.read_csv(stnlist_csv, encoding='latin1')\n",
    "\n",
    "start = pd.to_datetime(str(start_yr) + '-01-01')\n",
    "end = pd.to_datetime(str(end_yr) + '-12-31')\n",
    "\n",
    "for i, row in stnlist.iterrows():\n",
    "    stn_num = str(row['stn_num']).zfill(5)\n",
    "    stn_name = row['stn_name']\n",
    "    print(stn_num, stn_name)\n",
    "    \n",
    "    # Fulford Harbour (07330) does not have real-time data.\n",
    "    if stn_num == '07330':\n",
    "        continue\n",
    "    \n",
    "    df = real_time_data(stn_num, start, end)\n",
    "    df.to_csv(os.path.join(output_dir, f'{stn_num}_realtime_wl.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
